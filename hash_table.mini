import collections; // Assuming this provides Pair, Iterable2, Iterator2

// --- Helper Functions and Classes (Mostly Unchanged) ---

def i32_hasher(i : i32) -> i32 {
    i = (i + 0x7ed55d16) + (i << 12);
    i = (i bit_xor 0xc761c23c) bit_xor (i >> 19);
    i = (i + 0x165667b1) + (i << 5);
    i = (i + 0xd3a2646c) bit_xor (i << 9);
    i = (i + 0xfd7046c5) + (i << 3);
    i = (i bit_xor 0xb55a4f09) bit_xor (i >> 16);
    return i;
}

def i32_eq(a : i32, b : i32) -> Bool {
    return a == b;
}

class Tombstone {
    def init() {}
}

class Entry[K,V] {
    @key: K
    @value: V | Tombstone
    @hash: i32

    def init(@key: K, @value: V, @hash: i32) {}

    def init(@key: K, @value: Tombstone, @hash: i32) {}

    def key() -> K { return @key; }
    def value() -> V | Tombstone { return @value; }
    def hash() -> i32 { return @hash; }
}

// --- HashMap Implementation ---

class HashMap[K,V] extends Iterable2[Pair[K,V]] {
    @entries: Array[Entry[K,V] | Nil]
    @size: i32      // number of actual entries (key -> V)
    @load: i32      // number of occupied slots (key -> V or key -> Tombstone)
    @hasher: (K) -> i32
    @eq: (K, K) -> Bool

    def init(@hasher: (K) -> i32, @eq : (K, K) -> Bool) {
        @entries = Array[Entry[K,V] | Nil].new(16, 16);
        @size = 0;
        @load = 0;
        // @hasher and @eq are initialized by the parameter syntax
    }

    // Finds the slot index for a key.
    // Returns the index where the key is located, OR
    // Returns the index where the key should be inserted (first tombstone or nil).
    def find_slot(key: K, hash: i32) -> i32 {
        capacity = @entries.length();
        i = hash bit_and (capacity - 1); // Start index
        first_tombstone_idx = -1; // Index of first tombstone found

        while true {
            entry = @entries.unchecked_index(i);

            if entry is Nil {
                // Empty slot found. Key is not present beyond this point.
                // Return the first tombstone slot if available, otherwise this empty slot.
                if first_tombstone_idx == -1 { return i; }
                return first_tombstone_idx;
            }

            // entry must be Entry[K,V] here
            if entry is Entry[K, V] {

                // Key found (might be active or a tombstone marker for this key).
                if entry.hash() == hash and @eq.call(entry.key(), key) { return i; }

                // If it's an entry for a *different* key, check if it's a tombstone
                value_in_entry = entry.value(); // Get value to check type
                if value_in_entry is Tombstone {
                    if first_tombstone_idx == -1 {
                        first_tombstone_idx = i; // Record the first tombstone spot
                    }
                }
                // Else (it's an active entry for a different key), continue probing.

                // Move to the next slot (linear probing with wrap-around)
                i = (i + 1) bit_and (capacity - 1);

                // Loop termination is guaranteed because load factor < 1 ensures at least one nil slot.
                // Added break conditions above to ensure termination when a result is found.
            }
        }
    }

    def resize(new_capacity: i32) {
        old_entries = @entries;
        @entries = Array[Entry[K,V] | Nil].new(new_capacity, new_capacity); // Call as instance method
        @size = 0; // Reset size and load for the new table
        @load = 0;

        i = 0;
        while i < old_entries.length() {
            entry = old_entries.unchecked_index(i);
            // Re-insert only if it's a valid entry with a non-tombstone value
            if entry is Entry[K,V] {
                val = entry.value();
                if not (val is Tombstone) {
                    if val is V { // Check if the value is of type V (not Tombstone)
                        // Use internal insert to avoid redundant checks/resizes
                        self.insert_internal(entry.key(), val, entry.hash());
                    }
                }
            }
            i = i + 1;
        }
    }

    // Internal insert function used by resize, assumes capacity check already done.
    // Renamed from _insert_internal
    def insert_internal(key: K, value: V, hash: i32) {
         i = self.find_slot(key, hash);
         current_entry = @entries.unchecked_index(i);

         new_entry = Entry[K,V].new(key, value, hash);
         @entries.unchecked_insert(i, new_entry);

         if current_entry is Nil {
            // Inserted into an empty slot
            @size = @size + 1;
            @load = @load + 1;
         }
         if current_entry is Entry[K, V] {
             // current_entry must be Entry[K,V] here
             current_value = current_entry.value(); // Check the value type
             if current_value is Tombstone {
                 // Replaced a tombstone
                 @size = @size + 1;
                 // @load doesn't change (slot was already occupied)
             }
         }
    }

    def insert(key: K, value: V) {
        // Use integer arithmetic for load factor check (e.g., 7/10)
        // Check if load + 1 would exceed threshold to prevent exceeding capacity
        // Ensure length is not zero to avoid division by zero
        current_length = @entries.length();

        // Check load factor: (@load + 1) / current_length >= 0.7
        // Multiply to avoid float: (@load + 1) * 10 >= current_length * 7
        needs_resize = @entries.length() == 0 or (@load + 1) * 10 >= current_length * 7;

        if needs_resize {
             // Double the size, ensure it's at least 16 (a common default)
             new_capacity = current_length * 2;
             if new_capacity < 16 { new_capacity = 16; } // Ensure a minimum capacity
             self.resize(new_capacity);
        }

        hash = @hasher.call(key);
        // Use the internal insert which handles size/load updates correctly
        self.insert_internal(key, value, hash);
    }

    def get(key: K) -> V | Nil {
        hash = @hasher.call(key);
        i = self.find_slot(key, hash);
        entry = @entries.unchecked_index(i);

        if entry is Entry[K, V] {
            // find_slot ensures if an entry is returned, hash and key match.
            // now just check if the value is a Tombstone or the actual value V.
            val = entry.value();
            if not (val is Tombstone) { if val is V { return val; } }
            // If val is Tombstone, the key was deleted
        }
        // If entry is nil or holds a Tombstone for the key
        return nil;
    }

    def remove(key: K) -> V | Nil {
        hash = @hasher.call(key);
        i = self.find_slot(key, hash);
        entry = @entries.unchecked_index(i);

        if entry is Entry[K, V] {
            val = entry.value();
            if not (val is Tombstone) {
                if val is V { // Only remove if it's an active entry
                    // Create Tombstone entry, preserving key and hash for probing
                    tombstone_entry = Entry[K,V].new(entry.key(), Tombstone.new(), entry.hash());
                    @entries.unchecked_insert(i, tombstone_entry);
                    @size = @size - 1; // Active element count decreases
                    // @load remains the same (slot still occupied by tombstone)
                    return val; // Return the removed value
                }
            }
            // If val is Tombstone, key was already removed effectively
        }
        // If entry is nil or holds a Tombstone for the key
        return nil;
    }

    def clear() {
        // Re-initialize with default capacity
        @entries = Array[Entry[K,V] | Nil].new(16, 16); // Call as instance method
        @size = 0;
        @load = 0;
    }

    def size() -> i32 { return @size; }

    // --- Iterator Implementation ---
    def iterator() -> Iterator2[Pair[K,V]] {
        // Return an instance of the custom iterator class
        return HashMapIterator[K,V].new(@entries);
    }
}

// --- Custom Iterator Class ---
// needs to conform to Iterator2 interface
class HashMapIterator[K,V] extends Iterator2[Pair[K,V]] {
    @map_entries: Array[Entry[K,V] | Nil]
    @index: i32

    def init(@map_entries: Array[Entry[K,V] | Nil]) {
        @index = 0;
    }
    def next() -> Pair[K, V] | Nil {
        while @index < @map_entries.length() {
            entry = @map_entries.unchecked_index(@index);
            @index = @index + 1;
            if entry is Entry[K, V] {
                val = entry.value();
                if not (val is Tombstone) { if val is V { return Pair[K, V].new(entry.key(), val); } }
            }
        }
        return nil;
    }
}

// --- Helper Functions for String (Unchanged, assuming correct) ---
def string_hasher(s : String) -> i32 {
    hash : i32 = 0;
    seed : i32 = 31; // Common prime for polynomial rolling hash

    for c in s {
        // Assuming c.byte() returns an i32 representation of the character
        cast_val : i32 = c.byte();
        // Apply bitwise AnD to keep hash within positive i32 range
        // Using 0x7FFFFFFF ensures the sign bit is not set.
        // Alternative: use modulo a large prime if negative hashes are problematic
        hash = (hash * seed + cast_val) bit_and 0x7FFFFFFF;
    }
    return hash; // Result is already positive or zero
}

def string_eq(a : String, b : String) -> Bool {
    return a == b;
}

// --- Additions for Benchmarking ---

extern def clock() -> i64

// --- PRNG Class (Unchanged) ---
class PRNG {
    @seed: i32
    def init(initial_seed: i32) {
        if initial_seed <= 0 { @seed = 1; return; }
        @seed = initial_seed bit_and 0x7FFFFFFF;
    }
    def next() -> i32 {
        a : i32 = 1103515245; c : i32 = 12345;
        @seed = (@seed * a + c) bit_and 0x7FFFFFFF;
        return @seed;
    }
}

// --- Helper to print benchmark results (Modified for i64) ---
def print_benchmark_result(test_name: String, n: i32, duration: i64) { // n is i32, duration is i64
    IO.print(test_name);
    IO.print("  Operations: "); IO.print(n); // Print n as i32
    IO.print("  Total Time: "); IO.print(duration); IO.print(" ms"); // Print duration as i64

    // Calculate time per operation in microseconds using i64
    if n > 0 {
        ns_per_op : i64 = 0; // Use i64 for the result
        n_i64 : i64 = n; // Cast n to i64 for calculation (assuming 'as i64' syntax)
        zero : i64 = 0;
        million : i64 = 1000000;

        if duration > zero and n_i64 > zero {
            // Perform calculation in i64 to avoid overflow and truncation issues
             ns_per_op = (duration * million) / n_i64;
        }
        // Print the result as i64
        IO.print("  Time/Op:    ~"); IO.print(ns_per_op); IO.print(" ns");
    }
}

// --- Benchmarking Functions (Modified for i64 timing, lowercase n, verification) ---

def benchmark_insert_sequential(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    start_time: i64 = clock(); // Use i64
    i = 0;
    while i < n {
        map.insert(i, i + 1);
        i = i + 1;
    }
    end_time: i64 = clock(); // Use i64

    // --- Verification ---
    verification_passed = true;
    if n > 0 {
        last_val = map.get(n - 1);
        if last_val is Nil { verification_passed = false; }
        if last_val is i32 { if last_val != n { verification_passed = false; } } // Check value
        if map.size() != n { verification_passed = false; } // Check final size
    } else {
         if map.size() != 0 { verification_passed = false; }
    }
    // --- End Verification ---

    print_benchmark_result("Insert Sequential", n, end_time - start_time);
    IO.print("    Verification: ");
    if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
}

def benchmark_insert_random(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(123);
    keys_to_insert = Array[i32].new(n); // Assume capacity N is enough or it grows
    expected_size = 0; // Track expected size due to potential duplicates

    // Generate keys first
    temp_map_for_size_check = HashMap[i32, i32].new(i32_hasher, i32_eq); // To accurately get unique key count
    i = 0;
    last_key = -1; // Keep track of the last key generated
    while i < n {
        key = rng.next();
        keys_to_insert.unchecked_insert(i, key);
        if i == n-1 { last_key = key; } // Store last key for verification
        temp_map_for_size_check.insert(key, 1); // Use temp map to count unique keys
        i = i + 1;
    }
    expected_size = temp_map_for_size_check.size();
    temp_map_for_size_check = nil; // Allow garbage collection if applicable


    // Perform inserts
    start_time: i64 = clock(); // i64
    i = 0;
    while i < n {
        key = keys_to_insert.unchecked_index(i);
        map.insert(key, key + 1); // Value is key + 1
        i = i + 1;
    }
    end_time: i64 = clock(); // i64

    // --- Verification ---
    verification_passed = true;
    if n > 0 {
         // Check the value associated with the last generated key
         last_val = map.get(last_key);
         if last_val is Nil { verification_passed = false; }
         if last_val is i32 { if last_val != (last_key + 1) { verification_passed = false; } }
         // Check final size against unique keys inserted
         if map.size() != expected_size { verification_passed = false; }
    } else {
         if map.size() != 0 { verification_passed = false; }
    }
    // --- End Verification ---

    print_benchmark_result("Insert Random", n, end_time - start_time);
    IO.print("    Verification: ");
    if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    IO.print("    (Expected unique size: "); IO.print(expected_size); IO.print(")");

}


def benchmark_get_sequential_hit(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    expected_sum: i64 = 0; // Use i64 for sum to avoid overflow
    // Pre-fill
    i = 0;
    while i < n {
        value_to_insert = i + 1;
        value_i64 : i64 = value_to_insert;
        map.insert(i, value_to_insert);
        expected_sum = expected_sum + value_i64; // Calculate expected sum
        i = i + 1;
    }

    start_time: i64 = clock(); // i64
    actual_sum: i64 = 0; // Use i64 for sum
    i = 0;
    while i < n {
        val = map.get(i);
        if val is i32 {
            val_i64 : i64 = val; // Cast retrieved value
            actual_sum = actual_sum + val_i64;
        } 
        i = i + 1;
    }
    end_time: i64 = clock(); // i64

    // --- Verification ---
    // Compare the calculated sum with the expected sum
    verification_passed = (actual_sum == expected_sum);
    // --- End Verification ---

    print_benchmark_result("Get Sequential Hit", n, end_time - start_time);
    IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    // IO.print("    (Sum: "); IO.print(actual_sum); IO.print(")"); // Optional: print sum
}

def benchmark_get_random_hit(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(456);
    keys_present = Array[i32].new(n); // Assume capacity N or it grows
    expected_sum: i64 = 0; // Use i64

    // Pre-fill with random keys
    i = 0;
    while i < n {
        key = rng.next();
        value_to_insert = key + 1;
        // Handle potential duplicates during pre-fill for expected_sum calculation.
        // Only add to sum if the insert *doesn't* replace an existing key.
        // Or, simpler: just calculate expected sum based on keys_present array later.
        map.insert(key, value_to_insert);
        keys_present.unchecked_insert(i, key);
        i = i + 1;
    }

    // Calculate expected sum from the keys we *know* we inserted and will retrieve.
    // This avoids issues with duplicate keys during insertion phase affecting the sum.
    i = 0;
    while i < n {
         key = keys_present.unchecked_index(i);
         key_inc : i64 = key + 1;
         expected_sum = expected_sum + key_inc; // Value is key + 1
         i = i + 1;
    }


    // Now get the keys we know are present
    start_time: i64 = clock(); // i64
    actual_sum: i64 = 0; // i64
    i = 0;
    while i < n {
        key = keys_present.unchecked_index(i);
        val = map.get(key);
        if val is i32 {
            val_i64 : i64 = val; // Cast retrieved value
            actual_sum = actual_sum + val_i64;
        } 
        i = i + 1;
    }
    end_time: i64 = clock(); // i64

    // --- Verification ---
    verification_passed = (actual_sum == expected_sum);
    // --- End Verification ---

    print_benchmark_result("Get Random Hit", n, end_time - start_time);
     IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    // IO.print("    (Sum: "); IO.print(actual_sum); IO.print(")");
}

def benchmark_get_random_miss(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng_setup = PRNG.new(789);
    rng_miss = PRNG.new(987);

    // Pre-fill with some keys
    i = 0;
    while i < n {
        key = rng_setup.next();
        map.insert(key, key + 1);
        i = i + 1;
    }
    initial_size = map.size(); // Store size after setup

    // Generate *different* random keys to lookup
    keys_to_miss = Array[i32].new(n);
    i = 0;
    while i < n {
        keys_to_miss.unchecked_insert(i, rng_miss.next());
        i = i + 1;
    }


    start_time: i64 = clock(); // i64
    miss_count = 0;
    hit_count = 0; // Also count unexpected hits
    i = 0;
    while i < n {
        key = keys_to_miss.unchecked_index(i);
        val = map.get(key);
        if val is Nil { miss_count = miss_count + 1;}
        else { hit_count = hit_count + 1; }
        i = i + 1;
    }
    end_time: i64 = clock(); // i64

     // --- Verification ---
     // Expect mostly misses. A few hits are possible by chance, but should be low.
     // Define "low" somewhat arbitrarily, e.g., < 5% hits indicates likely correctness.
     verification_passed = (hit_count * 100 / n < 5); // Or just check hit_count is small
     // --- End Verification ---

    print_benchmark_result("Get Random Miss", n, end_time - start_time);
    IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    IO.print("    (Misses: "); IO.print(miss_count); IO.print(", Hits: "); IO.print(hit_count); IO.print(")");
}


def benchmark_remove_random(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(101112);
    keys_to_remove = Array[i32].new(n);

    // Pre-fill with random keys, ensuring we store unique keys if N is large
    temp_map_keys = HashMap[i32, Bool].new(i32_hasher, i32_eq);
    i = 0;
    keys_added_count = 0;
    while keys_added_count < n {
        key = rng.next();
        val = temp_map_keys.get(key);
        if val is Nil { // Ensure unique keys for removal test
            map.insert(key, key + 1);
            keys_to_remove.unchecked_insert(keys_added_count, key); // Store unique key
            temp_map_keys.insert(key, true);
            keys_added_count = keys_added_count + 1;
        }
         // Safety break if RNG produces too many duplicates for large N
         i = i+1; if i > n * 10 { break; }
    }
    n = keys_added_count; // Adjust n to the actual number of unique keys added/removed
    temp_map_keys = nil;


    // Remove the keys we know are present
    start_time: i64 = clock(); // i64
    remove_count = 0;
    i = 0;
    while i < n {
        key = keys_to_remove.unchecked_index(i);
        val = map.remove(key);
        if val is i32 { remove_count = remove_count + 1; }
        i = i + 1;
    }
    end_time: i64 = clock(); // i64

     // --- Verification ---
     verification_passed = true;
     // Check that remove_count matches the number of items we tried to remove
     if remove_count != n { verification_passed = false; }
     // Check that the map size is now 0
     if map.size() != 0 { verification_passed = false; }
     // Try getting one of the removed keys
     if n > 0 {
         key_to_check = keys_to_remove.unchecked_index(0);
         val = map.get(key_to_check);
         if val is i32 { verification_passed = false; } // Should be Nil
     }
     // --- End Verification ---

    print_benchmark_result("Remove Random", n, end_time - start_time);
    IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    IO.print("    (Items removed: "); IO.print(remove_count); IO.print(")");
}

// NOTE: benchmark_insert_remove_mix is harder to verify robustly without
// maintaining a separate reference list/map of expected contents.
// We'll skip detailed verification for this one, relying on the final size check.
def benchmark_insert_remove_mix(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(131415);
    op_count = n * 2;

    start_time: i64 = clock(); // i64
    i = 0;
    // This loop remains simplified (mostly inserts)
    while i < op_count {
        key = rng.next();
        map.insert(key, key+1);
        i = i + 1;
    }
    end_time: i64 = clock(); // i64
    final_size = map.size(); // Get size for verification print

    print_benchmark_result("Insert Heavy Mix", op_count, end_time - start_time);
    // Basic verification: just print the size, as the exact content is complex to track here.
    IO.print("    (final map size: "); IO.print(final_size); IO.print(")");
}


// --- Main Execution ---

IO.print("--- HashMap Benchmarks ---");

//n = 100000; // Use lowercase n, 100k operations
//n = 500000;
n = 1000000; // Use i64 for timing, so larger n might be okay now

benchmark_insert_sequential(n);
benchmark_insert_random(n);
benchmark_get_sequential_hit(n);
benchmark_get_random_hit(n);
benchmark_get_random_miss(n);
benchmark_remove_random(n);
benchmark_insert_remove_mix(n); // Simplified mix

IO.print("--- Benchmarks Complete ---");

// --- Original Example Usage (Keep or comment out) ---
// ... (rest of your original example code showing the 1789593040 bug) ...