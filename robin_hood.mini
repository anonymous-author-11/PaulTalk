import collections; // Assuming this provides Pair, Iterable2, Iterator2

// --- Helper Functions and Classes (Unchanged) ---

def i32_hasher(i : i32) -> i32 {
    // Same fast bit-mixing hash function
    i = (i + 0x7ed55d16) + (i << 12);
    i = (i bit_xor 0xc761c23c) bit_xor (i >> 19);
    i = (i + 0x165667b1) + (i << 5);
    i = (i + 0xd3a2646c) bit_xor (i << 9);
    i = (i + 0xfd7046c5) + (i << 3);
    i = (i bit_xor 0xb55a4f09) bit_xor (i >> 16);
    return i;
}

def i32_eq(a : i32, b : i32) -> Bool {
    return a == b;
}

class Tombstone {
    def init() {}
}

class Entry[K,V] {
    @hash: i32 // Store hash to avoid recomputing during probes
    @key: K
    @value: V | Tombstone

    def init(@key: K, @value: V, @hash: i32) {}
    def init(@key: K, @value: Tombstone, @hash: i32) {}

    def key() -> K { return @key; }
    def value() -> V | Tombstone { return @value; }
    def hash() -> i32 { return @hash; }
}

// --- HashMap Implementation (Robin Hood Probing) ---

class HashMap[K,V] extends Iterable2[Pair[K,V]] {
    @entries: Array[Entry[K,V] | Nil]
    @size: i32      // number of actual entries (key -> V)
    @load: i32      // number of occupied slots (key -> V or key -> Tombstone)
    @hasher: (K) -> i32
    @eq: (K, K) -> Bool

    def init(@hasher: (K) -> i32, @eq : (K, K) -> Bool) {
        @entries = Array[Entry[K,V] | Nil].new(16, 16);
        @size = 0;
        @load = 0;
    }

    // Helper to calculate probe distance (using safer non-negative approach).
    // Assumes capacity is a power of 2.
    def calculate_probe_distance(current_index: i32, element_hash: i32, mask: i32, capacity: i32) -> i32 {
        initial_index = element_hash bit_and mask;
        // Safer calculation: (current - initial + capacity) % capacity
        distance = (current_index - initial_index + capacity) bit_and mask;
        return distance;
    }

    // Finds the slot index for a key using LINEAR PROBING (for get/remove).
    // Returns the index where the key is located (and is active), OR -1 if not found or tombstoned.
    def find_slot(key: K, hash: i32) -> i32 {
        capacity = @entries.length();
        if capacity == 0 { return -1; }

        mask = capacity - 1;
        initial_index = hash bit_and mask;
        current_index = initial_index;
        probe_step = 0; // Our theoretical probe distance

        while true {
            entry_or_nil = @entries.unchecked_index(current_index);

            // --- Check 1: Empty slot ---
            if entry_or_nil is Nil {
                return -1; // Key definitely not present
            }

            // --- Check 2: Entry exists ---
            if entry_or_nil is Entry[K, V] {
                 existing_entry = entry_or_nil;
                 existing_hash = existing_entry.hash();

                 // --- Robin Hood Early Exit (Check first) ---
                 // Use the safer distance calculation
                 existing_entry_probe_distance = self.calculate_probe_distance(current_index, existing_hash, mask, capacity);
                 current_search_probe_distance = probe_step;
                 if current_search_probe_distance > existing_entry_probe_distance {
                      return -1; // Key cannot be further down this probe chain
                 }

                 // --- Key Match Check ---
                 if existing_hash == hash {
                     if @eq.call(existing_entry.key(), key) {
                         // Found the correct key! Now check if it's a tombstone.
                         val = existing_entry.value();
                         if val is Tombstone {
                             return -1; // Found key, but it's deleted. Treat as not found.
                         }
                         return current_index; // Found the active key. Success!
                     }
                     // Hash matched, key didn't (collision). Continue probing.
                 }
                 // Hash didn't match OR key didn't match. Continue probing.
                 // Correctly falls through to the linear probing step below.
            }

            // --- Linear Probing Step ---
            probe_step = probe_step + 1;
            current_index = (initial_index + probe_step) bit_and mask; // Wrap around

            // --- Safety Check ---
            if probe_step >= capacity {
                 // Should not happen in a correctly functioning map with load factor < 1
                 // Log error? For benchmark, just return -1.
                 // IO.print("WARN: find_slot looped through entire table.");
                 return -1;
            }
        } // End while loop
    }

    // Ensures capacity is a power of two, doubles if needed.
    // Using 80% load factor for Robin Hood.
    def ensure_capacity(required_load: i32) {
         current_length = @entries.length();
         needs_resize = current_length == 0 or required_load * 10 >= current_length * 8;

        if needs_resize {
             new_capacity = current_length * 2;
             if new_capacity < 16 { new_capacity = 16; }
             self.resize(new_capacity);
        }
    }


    // Resizes the internal array and rehashes all existing ACTIVE entries.
    def resize(new_capacity: i32) {
        old_entries = @entries;
        @entries = Array[Entry[K,V] | Nil].new(new_capacity, new_capacity);
        @size = 0;
        @load = 0;
        old_len = old_entries.length();
        i = 0;
        while i < old_len {
            entry = old_entries.unchecked_index(i);
            if entry is Entry[K,V] {
                val = entry.value();
                if not (val is Tombstone) {
                    if val is V { self.insert_internal(entry.key(), val, entry.hash()); }
                }
            }
            i = i + 1;
        }
    }

    // Internal insert function using Robin Hood probing with displacement.
    def insert_internal(key_to_insert: K, value_to_insert: V, hash_to_insert: i32) {
        capacity = @entries.length();
        mask = capacity - 1;

        current_key = key_to_insert;
        current_value = value_to_insert;
        current_hash = hash_to_insert;
        current_probe_distance = 0;
        probe_index = current_hash bit_and mask;

        while true {
            entry_or_nil = @entries.unchecked_index(probe_index);

            // --- Case 1: Empty Slot (Nil) ---
            if entry_or_nil is Nil {
                new_entry = Entry[K, V].new(current_key, current_value, current_hash);
                @entries.unchecked_insert(probe_index, new_entry);
                @size = @size + 1;
                @load = @load + 1;
                return;
            }

            // --- Case 2: Slot is occupied ---
            if entry_or_nil is Entry[K, V] {
                existing_entry = entry_or_nil;
                existing_hash = existing_entry.hash(); // Cache hash

                // --- Subcase 2a: Slot contains a Tombstone ---
                val = existing_entry.value();
                if val is Tombstone {
                    new_entry = Entry[K, V].new(current_key, current_value, current_hash);
                    @entries.unchecked_insert(probe_index, new_entry);
                    @size = @size + 1; // Replace tombstone -> size increases
                    // @load doesn't change
                    return;
                }

                // --- Subcase 2b: Slot contains an active Entry ---
                if existing_hash == current_hash {
                     if @eq.call(existing_entry.key(), current_key) {
                         // Key update
                         updated_entry = Entry[K, V].new(current_key, current_value, current_hash);
                         @entries.unchecked_insert(probe_index, updated_entry);
                         // size and load unchanged
                         return;
                     }
                }

                // --- Robin Hood Swap Logic ---
                // Use safer distance calculation
                existing_probe_distance = self.calculate_probe_distance(probe_index, existing_hash, mask, capacity);

                if current_probe_distance > existing_probe_distance {
                    // Swap
                    entry_to_place_in_slot = Entry[K, V].new(current_key, current_value, current_hash);
                    @entries.unchecked_insert(probe_index, entry_to_place_in_slot);

                    // Update carried item
                    current_key = existing_entry.key();
                    existing_value_temp = existing_entry.value(); // Known to be V here
                    if existing_value_temp is V { current_value = existing_value_temp; }
                    current_hash = existing_hash;
                    current_probe_distance = existing_probe_distance; // New carried distance
                }
                // Else (poorer or equal), keep carrying current item.
            }

            // --- Linear Probing Step ---
            current_probe_distance = current_probe_distance + 1;
            probe_index = (probe_index + 1) bit_and mask;

            // --- Safety Check ---
            if current_probe_distance >= capacity {
                 IO.print("ERROR: insert_internal loop exceeded capacity.");
                 // Force resize maybe? Or just return to avoid loop.
                 // For benchmark, maybe resize and retry is too complex.
                 // This indicates a fundamental issue if hit.
                 return;
            }
        } // End while true loop
    }

    // Public insert method
    def insert(key: K, value: V) {
        self.ensure_capacity(@load + 1);
        hash = @hasher.call(key);
        self.insert_internal(key, value, hash);
    }

    // Get value associated with key
    def get(key: K) -> V | Nil {
        hash = @hasher.call(key);
        i = self.find_slot(key, hash);
        if i == -1 { return nil; }

        entry_or_nil = @entries.unchecked_index(i); // find_slot guarantees this exists and is active
        if entry_or_nil is Entry[K, V] {
            val = entry_or_nil.value();
            if val is V { return val; } // Should always be true if i != -1
        }
        return nil; // Fallback
    }

    // Remove key and return its value, or Nil if not found.
    def remove(key: K) -> V | Nil {
        hash = @hasher.call(key);
        i = self.find_slot(key, hash);
        if i == -1 { return nil; } // Not found or already tombstoned

        entry_or_nil = @entries.unchecked_index(i); // find_slot guarantees this exists and is active
         if entry_or_nil is Entry[K, V] {
             val = entry_or_nil.value();
             if val is V { // Should always be true if i != -1
                  // Replace with Tombstone, preserving key and hash.
                  tombstone_entry = Entry[K,V].new(entry_or_nil.key(), Tombstone.new(), entry_or_nil.hash());
                  @entries.unchecked_insert(i, tombstone_entry);
                  @size = @size - 1;
                  // @load remains the same
                  return val;
             }
        }
        return nil; // Fallback
    }

    // Clear the map
    def clear() {
        @entries = Array[Entry[K,V] | Nil].new(16, 16);
        @size = 0;
        @load = 0;
    }

    // Return number of active key-value pairs
    def size() -> i32 { return @size; }

    // --- Iterator Implementation (Unchanged) ---
    def iterator() -> HashMapIterator[K,V] {
        return HashMapIterator[K,V].new(@entries);
    }
}

// --- Custom Iterator Class (Unchanged from original) ---
class HashMapIterator[K,V] extends Iterator2[Pair[K,V]] {
    @map_entries: Array[Entry[K,V] | Nil]
    @index: i32
    @length: i32 // Cache length for minor optimization

    def init(@map_entries: Array[Entry[K,V] | Nil]) {
        @index = 0;
        @length = @map_entries.length(); // Cache length
    }

    def next() -> Pair[K, V] | Nil {
        while @index < @length { // Use cached length
            entry_or_nil = @map_entries.unchecked_index(@index);
            @index = @index + 1; // Increment index for next call

            if entry_or_nil is Entry[K, V] {
                val = entry_or_nil.value();
                if not (val is Tombstone) {
                    if val is V { return Pair[K, V].new(entry_or_nil.key(), val); }
                 }
            }
            // Continue loop if Nil or Tombstone
        }
        return nil; // End of iteration
    }
}

// --- Helper Functions for String (Unchanged) ---
def string_hasher(s : String) -> i32 {
    hash : i32 = 0;
    seed : i32 = 31;
    for c in s {
        cast_val : i32 = c.byte();
        hash = (hash * seed + cast_val) bit_and 0x7FFFFFFF;
    }
    return hash;
}

def string_eq(a : String, b : String) -> Bool {
    return a == b;
}

// --- Additions for Benchmarking (Unchanged) ---
extern def clock() -> i64

// --- PRNG Class (Unchanged) ---
class PRNG {
    @seed: i32
    def init(initial_seed: i32) {
        if initial_seed <= 0 { @seed = 1; return; }
        @seed = initial_seed bit_and 0x7FFFFFFF;
    }
    def next() -> i32 {
        a : i32 = 1103515245; c : i32 = 12345;
        @seed = (@seed * a + c) bit_and 0x7FFFFFFF;
        return @seed;
    }
}

// --- Helper to print benchmark results (Unchanged) ---
def print_benchmark_result(test_name: String, n: i32, duration: i64) {
    IO.print(test_name);
    IO.print("  Operations: "); IO.print(n);
    IO.print("  Total Time: "); IO.print(duration); IO.print(" ms");
    if n > 0 {
        ns_per_op : i64 = 0;
        n_i64 : i64 = n;
        zero : i64 = 0;
        million : i64 = 1000000;
        if duration > zero and n_i64 > zero {
             ns_per_op = (duration * million) / n_i64;
        }
        IO.print("  Time/Op:    ~"); IO.print(ns_per_op); IO.print(" ns");
    }
}

// --- Benchmarking Functions (Unchanged - Verification logic assumes map works) ---

def benchmark_insert_sequential(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    start_time: i64 = clock();
    i = 0;
    while i < n {
        map.insert(i, i + 1);
        i = i + 1;
    }
    end_time: i64 = clock();
    verification_passed = true;
    if n > 0 {
        last_val = map.get(n - 1);
        if last_val is Nil { verification_passed = false; }
        if last_val is i32 { if last_val != n { verification_passed = false; } }
        if map.size() != n { verification_passed = false; }
    } else {
         if map.size() != 0 { verification_passed = false; }
    }
    print_benchmark_result("Insert Sequential", n, end_time - start_time);
    IO.print("    Verification: ");
    if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
}

def benchmark_insert_random(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(123);
    keys_to_insert = Array[i32].new(n);
    expected_size = 0;
    temp_map_for_size_check = HashMap[i32, i32].new(i32_hasher, i32_eq);
    i = 0;
    last_key = -1;
    while i < n {
        key = rng.next();
        keys_to_insert.unchecked_insert(i, key);
        if i == n-1 { last_key = key; }
        temp_map_for_size_check.insert(key, 1);
        i = i + 1;
    }
    expected_size = temp_map_for_size_check.size();
    temp_map_for_size_check = nil;
    start_time: i64 = clock();
    i = 0;
    while i < n {
        key = keys_to_insert.unchecked_index(i);
        map.insert(key, key + 1);
        i = i + 1;
    }
    end_time: i64 = clock();
    verification_passed = true;
    if n > 0 {
         last_val = map.get(last_key);
         if last_val is Nil { verification_passed = false; }
         if last_val is i32 { if last_val != (last_key + 1) { verification_passed = false; } }
         // Note: The comparison map.size() != expected_size might be slightly flaky
         // if the last key inserted happened to be a duplicate overwritten earlier.
         // A more robust check would be to iterate the final map and compare keys/values.
         // However, for the benchmark's purpose, checking the final size against expected unique count
         // and checking the value of the *last generated key* provides reasonable verification.
         if map.size() != expected_size { verification_passed = false; }
    } else {
         if map.size() != 0 { verification_passed = false; }
    }
    print_benchmark_result("Insert Random", n, end_time - start_time);
    IO.print("    Verification: ");
    if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    IO.print("    (Expected unique size: "); IO.print(expected_size); IO.print(")");
}


def benchmark_get_sequential_hit(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    expected_sum: i64 = 0;
    i = 0;
    while i < n {
        value_to_insert = i + 1;
        value_i64 : i64 = value_to_insert;
        map.insert(i, value_to_insert);
        expected_sum = expected_sum + value_i64;
        i = i + 1;
    }
    start_time: i64 = clock();
    actual_sum: i64 = 0;
    i = 0;
    while i < n {
        val = map.get(i);
        if val is i32 {
            val_i64 : i64 = val;
            actual_sum = actual_sum + val_i64;
        }
        i = i + 1;
    }
    end_time: i64 = clock();
    verification_passed = (actual_sum == expected_sum);
    print_benchmark_result("Get Sequential Hit", n, end_time - start_time);
    IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
}

def benchmark_get_random_hit(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(456);
    keys_present = Array[i32].new(n);
    expected_sum: i64 = 0;
    i = 0;
    // Pre-populate map and calculate expected sum based on inserted values
    temp_map_keys = HashMap[i32, Bool].new(i32_hasher, i32_eq);
    keys_added_count = 0;
    safety_counter = 0;
    while keys_added_count < n and safety_counter < n*10 {
        key = rng.next();
        val = temp_map_keys.get(key);
        if val is Nil {
            value_to_insert = key + 1;
            map.insert(key, value_to_insert);
            keys_present.unchecked_insert(keys_added_count, key);
            value_i64 : i64 = value_to_insert;
            expected_sum = expected_sum + value_i64; // Sum the actual inserted values
            temp_map_keys.insert(key, true);
            keys_added_count = keys_added_count + 1;
        }
        safety_counter = safety_counter + 1;
    }
    n_actual = keys_added_count; // Use actual count of unique keys
    temp_map_keys = nil;

    start_time: i64 = clock();
    actual_sum: i64 = 0;
    get_failures = 0;
    i = 0;
    while i < n_actual { // Iterate over the keys we actually inserted
        key = keys_present.unchecked_index(i);
        val = map.get(key);
        if val is i32 {
            val_i64 : i64 = val;
            actual_sum = actual_sum + val_i64;
        } else {
            get_failures = get_failures + 1; // Should not happen
        }
        i = i + 1;
    }
    end_time: i64 = clock();
    verification_passed = (actual_sum == expected_sum and get_failures == 0);
    print_benchmark_result("Get Random Hit", n_actual, end_time - start_time); // Report based on actual keys
     IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
}

def benchmark_get_random_miss(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng_setup = PRNG.new(789);
    rng_miss = PRNG.new(987); // Different seed for misses
    temp_map_keys_setup = HashMap[i32, Bool].new(i32_hasher, i32_eq);
    keys_to_miss = Array[i32].new(n);

    // Phase 1: Populate map
    keys_added_count = 0;
    safety_counter = 0;
    while keys_added_count < n and safety_counter < n*10 {
        key = rng_setup.next();
        val = temp_map_keys_setup.get(key);
        if val is Nil {
            map.insert(key, key + 1);
            temp_map_keys_setup.insert(key, true);
            keys_added_count = keys_added_count + 1;
        }
        safety_counter = safety_counter + 1;
    }

    // Phase 2: Generate keys unlikely to be in the map
    miss_keys_generated = 0;
    safety_counter = 0;
    while miss_keys_generated < n and safety_counter < n*10 {
        key = rng_miss.next();
        // Check if this miss candidate key was actually inserted during setup
        val = temp_map_keys_setup.get(key);
        if val is Nil {
            keys_to_miss.unchecked_insert(miss_keys_generated, key);
            miss_keys_generated = miss_keys_generated + 1;
        }
        safety_counter = safety_counter + 1;
    }
    n_actual_misses = miss_keys_generated; // Actual number of miss keys to test
    temp_map_keys_setup = nil;


    // Phase 3: Benchmark get on miss keys
    start_time: i64 = clock();
    miss_count = 0;
    hit_count = 0; // Should ideally be 0
    i = 0;
    while i < n_actual_misses {
        key = keys_to_miss.unchecked_index(i);
        val = map.get(key);
        if val is Nil { miss_count = miss_count + 1;}
        else { hit_count = hit_count + 1; } // Unexpected hit
        i = i + 1;
    }
    end_time: i64 = clock();
     // Allow a very small percentage of accidental hits due to hash collisions or dense key space.
     // E.g. less than 1% hits. Modify threshold if needed.
     allowable_hits = n_actual_misses / 100;
     verification_passed = (hit_count <= allowable_hits);
     print_benchmark_result("Get Random Miss", n_actual_misses, end_time - start_time); // Report based on actual keys
    IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    IO.print("    (Misses: "); IO.print(miss_count); IO.print(", Hits: "); IO.print(hit_count); IO.print(")");
}


def benchmark_remove_random(n: i32) {
    map = HashMap[i32, i32].new(i32_hasher, i32_eq);
    rng = PRNG.new(101112);
    keys_to_remove = Array[i32].new(n);
    temp_map_keys = HashMap[i32, Bool].new(i32_hasher, i32_eq);
    keys_added_count = 0;
    safety_counter = 0;

    // Phase 1: Populate map with unique keys
    while keys_added_count < n and safety_counter < n*10 {
        key = rng.next();
        val = temp_map_keys.get(key);
        if val is Nil {
            map.insert(key, key + 1);
            keys_to_remove.unchecked_insert(keys_added_count, key);
            temp_map_keys.insert(key, true);
            keys_added_count = keys_added_count + 1;
        }
         safety_counter = safety_counter + 1;
    }
    n_actual = keys_added_count; // Use actual count
    temp_map_keys = nil;

    // Phase 2: Benchmark remove
    start_time: i64 = clock();
    remove_count = 0;
    remove_failures = 0;
    i = 0;
    while i < n_actual {
        key = keys_to_remove.unchecked_index(i);
        val = map.remove(key);
        if val is i32 { remove_count = remove_count + 1; }
        else { remove_failures = remove_failures + 1; } // Should not happen
        i = i + 1;
    }
    end_time: i64 = clock();
     verification_passed = true;
     if remove_count != n_actual { verification_passed = false; }
     if remove_failures != 0 { verification_passed = false; }
     if map.size() != 0 { verification_passed = false; }
     // Double check: try getting a removed key
     if n_actual > 0 {
         key_to_check = keys_to_remove.unchecked_index(0);
         val = map.get(key_to_check);
         if val is i32 { verification_passed = false; } // Should be nil
     }
     print_benchmark_result("Remove Random", n_actual, end_time - start_time); // Report based on actual keys
    IO.print("    Verification: "); if verification_passed { IO.print("PASS"); } else { IO.print("FAIL"); }
    IO.print("    (Items removed: "); IO.print(remove_count); IO.print(", Failures: "); IO.print(remove_failures); IO.print(")");
}

// --- Main Execution ---

IO.print("--- HashMap Benchmarks (Robin Hood Probing) ---"); // Updated title

//n = 100000;
//n = 500000;
n = 1000000; // Use i64 for timing

benchmark_insert_sequential(n);
benchmark_insert_random(n);
benchmark_get_sequential_hit(n);
benchmark_get_random_hit(n);
benchmark_get_random_miss(n);
benchmark_remove_random(n);

IO.print("--- Benchmarks Complete ---");