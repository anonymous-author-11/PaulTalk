import std;

// records time in milliseconds
extern def clock() -> i64

// compiles to:
// define i32 @min(i32 %0, i32 %1) {
//   %3 = call i32 @llvm.smin.i32(i32 %0, i32 %1)
//   ret i32 %3
// }
def min(a : i32, b : i32) -> i32 {
    if a < b { return a; }
    return b;
}

// compiles to:
// define <4 x f64> @simd_add(<4 x f64> %0, <4 x f64> %1) {
//   %3 = add <4 x f64> %1, %0
//   ret <4 x f64> %3
// }
def simd_add(a : Tuple[4 x f64], b : Tuple[4 x f64]) -> Tuple[4 x f64] {
    return (a.[0] + b.[0], a.[1] + b.[1], a.[2] + b.[2], a.[3] + b.[3]);
}

// compiles to:
// define <4 x f64> @simd_mul(<4 x f64> %0, <4 x f64> %1) {
//   %3 = mul <4 x f64> %1, %0
//   ret <4 x f64> %3
// }
def simd_mul(a : Tuple[4 x f64], b : Tuple[4 x f64]) -> Tuple[4 x f64] {
    return (a.[0] * b.[0], a.[1] * b.[1], a.[2] * b.[2], a.[3] * b.[3]);
}

// simd_reduce compiles to an @llvm.vector.reduce intrinsic but simd_reduce_inner does not, though the former simply calls the latter
// This is an interesting LLVM quirk

// compiles to:
// define f64 @simd_reduce(<4 x f64> %0) {
//   %2 = call f64 @llvm.vector.reduce.add.v4f64(<4 x f64> %0)
//   ret f64 %2
// }
def simd_reduce(a : Tuple[4 x f64]) -> f64 {
    return simd_reduce_inner(a.[0], a.[1], a.[2], a.[3]);
}

// compiles to:
// define f64 @simd_reduce_inner(f64 %0, f64 %1, f64 %2, f64 %3) {
//   %5 = add f64 %1, %0
//   %6 = add f64 %5, %2
//   %7 = add f64 %6, %3
//   ret f64 %7
// }
def simd_reduce_inner(a : f64, b : f64, c : f64, d : f64) -> f64 {
    return a + b + c + d;
}

class Matrix {
    @data : Buffer[f64]
    @rows : i32
    @cols : i32

    // A subtype could override this to do something adaptive
    def Self.block_size() -> i32 { return 32; }

    def init(@rows : i32, @cols : i32) {
        @data = Buffer[f64].new(@rows * @cols);
    }

    def data() -> Buffer[f64] { return @data; }
    def rows() -> i32 { return @rows; }
    def cols() -> i32 { return @cols; }
    
    def row_idx() -> Range { return 0:(@rows - 1); }
    def col_idx() -> Range { return 0:(@cols - 1); }

    def set(row : i32, col : i32, value : f64) {
        @data.[col * @rows + row] = value;
    }

    def set_simd(start_row : i32, col : i32, values : Tuple[4 x f64]) {
        data = @data;
        rows = @rows;
        data.[col * rows + start_row + 0] = values.[0];
        data.[col * rows + start_row + 1] = values.[1];
        data.[col * rows + start_row + 2] = values.[2];
        data.[col * rows + start_row + 3] = values.[3];
    }

    def get(row : i32, col : i32) -> f64 {
        return @data.[col * @rows + row];
    }

    def get_simd(start_row : i32, col : i32) -> Tuple[4 x f64] {
        data = @data;
        rows = @rows;
        a = data.[col * rows + start_row + 0];
        b = data.[col * rows + start_row + 1];
        c = data.[col * rows + start_row + 2];
        d = data.[col * rows + start_row + 3];
        return (a, b, c, d);
    }

    def *(other : Matrix) -> Matrix {
        if @cols != other.rows() { yield(Exception.new()); }
        
        result = Matrix.new(@rows, other.cols());
        
        m = @rows;
        p = @cols;
        n = other.cols();

        block_size = Self.block_size();
        row_blocks_idx = self.row_idx().step(block_size);
        col_blocks_idx = self.col_idx().step(block_size);
        other_col_blocks_idx = other.col_idx().step(block_size);

        for ii in row_blocks_idx {
            for jj in other_col_blocks_idx {
                for kk in col_blocks_idx {
                    
                    i_limit_block = min(ii + block_size, m);
                    j_limit_block = min(jj + block_size, n);
                    k_limit_block = min(kk + block_size, p);

                    for j_block in jj:(j_limit_block - 1) {
                        for k_block in kk:(k_limit_block - 1) {
                            b_kj = other.get(k_block, j_block);
                            if b_kj == 0.0 { continue; }

                            i_block = ii;
                            while i_block <= i_limit_block - 4 {
                                a_vec = self.get_simd(i_block, k_block);
                                b_vec = (b_kj, b_kj, b_kj, b_kj);
                                c_vec = result.get_simd(i_block, j_block);
                                new_c_vec = simd_add(simd_mul(a_vec, b_vec), c_vec);
                                result.set_simd(i_block, j_block, new_c_vec);
                                i_block = i_block + 4;
                            }
                            
                            while i_block < i_limit_block {
                                c_val = result.get(i_block, j_block);
                                a_val = self.get(i_block, k_block);
                                result.set(i_block, j_block, c_val + a_val * b_kj);
                                i_block = i_block + 1;
                            }
                        }
                    }
                }
            }
        }
        return result;
    }
}

def benchmark_matrix_multiplication() {
    size = 2048;
    
    matrix1 = Matrix.new(size, size);
    matrix2 = Matrix.new(size, size);
    
    for i in 0:(size - 1) {
        for j in 0:(size - 1) {
            val1 = (i + j) % 10;
            val2 = (i - j + 10) % 10;
            matrix1.set(i, j, val1 as f64); 
            matrix2.set(i, j, val2 as f64);
        }
    }
    
    start_time = clock();
    result = matrix1 * matrix2;
    end_time = clock();
    
    time_taken = end_time - start_time;
    
    IO.print("Matrix multiplication");
    IO.print(size);
    IO.print("x");
    IO.print(size);
    IO.print("Time taken:");
    IO.print(time_taken);
    
    sum = 0.0;
    for i in 0:(size - 1) { sum = sum + result.get(0, i); }
    IO.print("Sum of first row (for verification):");
    IO.print(sum);
}

benchmark_matrix_multiplication();
